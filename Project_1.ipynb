{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "\n",
    "#Pkg.add(\"CSV\")\n",
    "#Pkg.add(\"Random\")\n",
    "\n",
    "using Zygote\n",
    "using Flux\n",
    "using Flux: onehotbatch, onecold, crossentropy\n",
    "using MLDatasets\n",
    "#using CUDA\n",
    "using Statistics\n",
    "using Plots\n",
    "using Images\n",
    "using Colors\n",
    "using ImageTransformations\n",
    "using MLUtils\n",
    "using CSV\n",
    "using Random\n",
    "using DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\"\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_true, train_y_true = CIFAR10(:train)[:];\n",
    "\n",
    "# Select the first image (H, W, C) = (32, 32, 3)\n",
    "image_data = Float64.(train_x_true[:, :, :, 3])   # Normalize first\n",
    "\n",
    "# Display image correctly (RGB expects (3, H, W))\n",
    "plot(colorview(RGB, permutedims(image_flipped, (3, 1, 2))))\n",
    "plot!(title=(class_names[train_y_true[3] ]))\n",
    "plot!(xticks = false, yticks = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = CIFAR10(:train).features, CIFAR10(:train).targets\n",
    "test_x, test_y = CIFAR10(:test).features, CIFAR10(:test).targets\n",
    "\n",
    "train_x = permutedims(Float32.(train_x) , (1,2,3,4))  \n",
    "test_x = permutedims(Float32.(test_x) , (1,2,3,4)) \n",
    "\n",
    "train_y = onehotbatch(vec(train_y), 0:9)  \n",
    "test_y = onehotbatch(vec(test_y), 0:9)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights are learned\n",
    "\n",
    "conv1 = Conv((3,3), 3=>16, relu, pad=1)\n",
    "pool1 = MaxPool((2,2))\n",
    "conv2 = Conv((3,3), 16=>32, relu, pad=1)\n",
    "pool2 = MaxPool((2,2))\n",
    "conv3 = Conv((3,3), 32=>64, relu, pad=1)\n",
    "pool3 = MaxPool((2,2))\n",
    "conv4 = Conv((3,3), 64=>128, relu, pad=1)\n",
    "pool4 = MaxPool((2,2))\n",
    "flatten = Flux.flatten\n",
    "dense1 = Dense(512, 1024, relu)\n",
    "dense2 = Dense(1024, 512)\n",
    "dense3 = Dense(512, 10)\n",
    "\n",
    "model = Chain(\n",
    "    conv1,\n",
    "    pool1,\n",
    "    BatchNorm(16),\n",
    "    conv2,\n",
    "    pool2,\n",
    "    BatchNorm(32),\n",
    "    conv3,\n",
    "    pool3,\n",
    "    BatchNorm(64),\n",
    "    conv4,\n",
    "    pool4,\n",
    "    BatchNorm(128),\n",
    "    flatten,\n",
    "    dense1,\n",
    "    dense2,\n",
    "    dense3,\n",
    "    softmax\n",
    ")\n",
    "\n",
    "loss(m, x, y) = crossentropy(m(x), y)\n",
    "\n",
    "opt = ADAM();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model!(model, train_X, train_Y, opt, epochs, batch_size)\n",
    "    data_loader = Flux.DataLoader((train_X, train_Y), batchsize=batch_size, shuffle=true)\n",
    "    \n",
    "    opt_state = Flux.setup(opt, model)  \n",
    "    total_loss = []\n",
    "\n",
    "    for epoch in 1:epochs\n",
    "        epoch_loss = 0\n",
    "        for (x, y) in data_loader\n",
    "            gs = Flux.gradient(model -> Flux.Losses.crossentropy(model(x), y), model)[1]  \n",
    "            Flux.update!(opt_state, Flux.trainable(model), gs)\n",
    "            epoch_loss += Flux.Losses.crossentropy(model(x), y)\n",
    "        end\n",
    "        println(\"Epoch $epoch complete\")\n",
    "        push!(total_loss, epoch_loss)\n",
    "    end\n",
    "    return total_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 64;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = train_model!(model, train_x, train_y, opt, epochs, batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plot(1:epochs, loss_list, xlabel=\"Epoch\", ylabel=\"Loss\", title=\"Loss vs. Epoch\", legend=false, xticks=false, yticks=false)\n",
    "display(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_layers(model, train_x[:, :, :, 1:1])\n",
    "\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "println(\"Test Accuracy: \", accuracy(test_x, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function visualize_layer(input_data, layer, filter_labels)\n",
    "    output = layer(input_data)  # Apply the convolutional layer\n",
    "\n",
    "    num_filters = size(output, 4)  # Number of output channels\n",
    "\n",
    "    # Create input plot\n",
    "    input_plot = heatmap(input_data[:, :, 1, 1], axis=nothing, title=label, xticks=false, yticks=false, colorbar=false,\n",
    "    #color =:acton, \n",
    "    aspect_ratio=:equal\n",
    "    )\n",
    "\n",
    "    # Create output plots for each filter response with labels\n",
    "    output_plots = [\n",
    "        heatmap(output[:, :, 1, i], axis=nothing, \n",
    "                title=filter_labels,\n",
    "                xticks=false, yticks=false, colorbar=false,\n",
    "                #color =:acton\n",
    "                ) \n",
    "        for i in 1:num_filters\n",
    "    ]\n",
    "\n",
    "    # Arrange plots in a grid (side by side)\n",
    "    plot(input_plot, output_plots..., layout=(1, num_filters + 1))\n",
    "end\n",
    "\n",
    "using Flux\n",
    "\n",
    "# Define each filter as a 3x3 matrix\n",
    "\n",
    "# Laplacian\n",
    "f1 = [ 0  -1  0; -1  4 -1;  0  -1  0 ]\n",
    "\n",
    "# Sharpening\n",
    "f2 = [ 0  -1  0; -1  9 -1;  0  -1  0 ]\n",
    "\n",
    "# Sobels\n",
    "f3 = [ 1   2  1;  0  0  0; -1  -2 -1 ]\n",
    "f4 = [ 1   0 -1;  2  0 -2;  1   0 -1 ]\n",
    "\n",
    "# Gaussian Blur\n",
    "f5 = (1/16).*[ 1   2  1;  2  4  2;  1   2  1 ]\n",
    "f7 = (1/273).*[ 1 4 7 4 1; 4 16 26 16 4; 7 26 41 26 7; 4 16 26 16 4; 1 4 7 4 1 ] \n",
    "f8 = (1/1003) .* [ 0 0 1 2 1 0 0; 0 3 13 22 13 3 0; 1 13 59 97 59 13 1; 2 22 97 159 97 22 2; 1 13 59 97 59 13 1; 0 3 13 22 13 3 0; 0 0 1 2 1 0 0 ]\n",
    "\n",
    "# Embossing\n",
    "f6 = [-2  -1  0; -1  1  1;  0   1  2 ]\n",
    "\n",
    "# Box Blur\n",
    "f9 = (1/9) .* [ 1 1 1; 1 1 1; 1 1 1 ]\n",
    "\n",
    "\n",
    "f10 = (-1/256).*[ 1 4 6 4 1; 4 16 24 16 4; 6 24 -476 24 6; 4 16 24 16 4; 1 4 6 4 1 ]\n",
    "\n",
    "# some custom filter\n",
    "f11 = [ 1 0 1 0 1; 0 0 0 0 0; 1 0 10 0 1; 0 0 0 0 0; 1 0 1 0 1]\n",
    "\n",
    "# Inverse Gaussian Blur\n",
    "f12 = (1/14).*[ 20 5 20; 5 0 5; 20 5 20]\n",
    "\n",
    "# Alternative Sobels\n",
    "f13 = [ 3 0 -3; 10 0 -10; 3 0 -3]\n",
    "f14 = [ 3 10 3; 0 0 0; -3 -10 -3]\n",
    "\n",
    "# Scharr Operator\n",
    "f15 = [47 0 -47; 162 0 -162; 47 0 -47]\n",
    "f17 = [47 162 47; 0 0 0; -47 -162 -47]\n",
    "\n",
    "# Reshape each filter to include the input channel and output channel dimensions (3, 3, 1, 1)\n",
    "f1_tensor = reshape(f1, (3, 3, 1, 1))\n",
    "f2_tensor = reshape(f2, (3, 3, 1, 1))\n",
    "f3_tensor = reshape(f3, (3, 3, 1, 1))\n",
    "f4_tensor = reshape(f4, (3, 3, 1, 1))\n",
    "f5_tensor = reshape(f5, (3, 3, 1, 1))\n",
    "f6_tensor = reshape(f6, (3, 3, 1, 1))\n",
    "f7_tensor = reshape(f7, (5, 5, 1, 1))\n",
    "f8_tensor = reshape(f8, (7, 7, 1, 1))\n",
    "f9_tensor = reshape(f9, (3, 3, 1, 1))\n",
    "f10_tensor = reshape(f10, (5, 5, 1, 1))\n",
    "f11_tensor = reshape(f11, (5, 5, 1, 1))\n",
    "f12_tensor = reshape(f12, (3, 3, 1, 1))\n",
    "f13_tensor = reshape(f13, (3, 3, 1, 1))\n",
    "f14_tensor = reshape(f14, (3, 3, 1, 1))\n",
    "f15_tensor = reshape(f15, (3, 3, 1, 1))\n",
    "f17_tensor = reshape(f17, (3, 3, 1, 1))\n",
    "\n",
    "\n",
    "\n",
    "# Define filter labels corresponding to their function\n",
    "filter_labels = [\n",
    "    \"Laplacian (Edge Detection)\", \n",
    "    \"Sharpening\", \n",
    "    \"Sobel (Vertical Edges)\", \n",
    "    \"Sobel (Horizontal Edges)\", \n",
    "    \"Gaussian Blur\",\n",
    "    \"Embossing\",\n",
    "    \"Large Gaussian Blur\",\n",
    "    \"Super Large Gaussian Blur\",\n",
    "    \"Box Blur\",\n",
    "    \"Unsharp Masking\",\n",
    "    \"Every Other\",\n",
    "    \"Inverse Gaussian Blur\",\n",
    "    \"Alternative Sobel (Vertical Edges)\",\n",
    "    \"Alternative Sobel (Horizontal Edges)\",\n",
    "    \"Scharr Operator (Vertical Edges)\",\n",
    "    \"Empty\",\n",
    "    \"Scharr Operator (Horizontal Edges)\"\n",
    "];\n",
    "\n",
    "n = length(filter_labels)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce types of padding \n",
    "\n",
    "pad_set = 1\n",
    "stride_set = 1\n",
    "choice = 170\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = train_x[:, :, :, choice:choice];\n",
    "\n",
    "image_data = Float64.(train_x_true[:, :, :, choice])   # Normalize first\n",
    "\n",
    "image_flipped = reverse(image_data, dims=1)\n",
    "\n",
    "plot(colorview(RGB, permutedims(image_flipped, (3, 1, 2))))\n",
    "image_label = class_names[train_y_true[choice] + 1]\n",
    "plot!(title=image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1 = Conv((3, 3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_1.weight .=f1_tensor\n",
    "\n",
    "conv_layer_2 = Conv((3, 3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_2.weight .=f2_tensor\n",
    "\n",
    "conv_layer_3 = Conv((3, 3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_3.weight .=f3_tensor\n",
    "\n",
    "conv_layer_4 = Conv((3, 3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_4.weight .=f4_tensor\n",
    "\n",
    "conv_layer_5 = Conv((3, 3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_5.weight .=f5_tensor\n",
    "\n",
    "conv_layer_6 = Conv((3, 3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_6.weight .=f6_tensor;\n",
    "\n",
    "conv_layer_7 = Conv((5,5), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_7.weight .=f7_tensor;\n",
    "\n",
    "conv_layer_8 = Conv((7,7), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_8.weight .=f8_tensor;\n",
    "\n",
    "conv_layer_9 = Conv((3,3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_9.weight .=f9_tensor;\n",
    "\n",
    "conv_layer_10 = Conv((5,5), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_10.weight .=f10_tensor;\n",
    "\n",
    "conv_layer_11 = Conv((5,5), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_11.weight .=f11_tensor;\n",
    "\n",
    "conv_layer_12 = Conv((3,3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_12.weight .=f12_tensor;\n",
    "\n",
    "conv_layer_13 = Conv((3,3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_13.weight .=f13_tensor;\n",
    "\n",
    "conv_layer_14 = Conv((3,3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_14.weight .=f14_tensor;\n",
    "\n",
    "conv_layer_15 = Conv((3,3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_15.weight .=f15_tensor;\n",
    "\n",
    "conv_layer_17 = Conv((3,3), 3 => n, pad=pad_set, stride = stride_set)\n",
    "conv_layer_17.weight .=f17_tensor;\n",
    "\n",
    "\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_1, filter_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_2, filter_labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_3, filter_labels[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_4, filter_labels[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_5, filter_labels[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_7, filter_labels[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_8, filter_labels[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_9, filter_labels[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_6, filter_labels[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_10, filter_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_11, filter_labels[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_12, filter_labels[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_13, filter_labels[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_14, filter_labels[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_15, filter_labels[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_layer(input_data, conv_layer_17, filter_labels[17])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
